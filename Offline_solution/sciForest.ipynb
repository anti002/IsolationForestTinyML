{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "from sklearn.metrics import average_precision_score\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of inliers and outliers\n",
    "n_samples = 256\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0]\n",
    "\n",
    "# Compare given detectors under given settings\n",
    "# Initialize the data\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.zeros(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(42)\n",
    "# Define nine outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    'Isolation Forest': IsolationForest(n_estimators= 100, \n",
    "                                random_state=random_state, max_samples=256, bootstrap = False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_iforest.py:289: UserWarning: max_samples (256) is greater than the total number of samples (214). max_samples will be set to n_samples for estimation.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x24de4484220>,\n",
       "  <matplotlib.lines.Line2D at 0x24de44844f0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x24de4484850>,\n",
       "  <matplotlib.lines.Line2D at 0x24de4484a90>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x24de246ef10>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x24de4484d60>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x24de4495070>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the models with the generated data and \n",
    "# compare model performances\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    #X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    #X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    #X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    #X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "    data = scipy.io.loadmat('C:\\\\Users\\\\anton\\\\OneDrive\\\\Skrivbord\\\\Thesis_Code\\\\IsolationForestTinyML\\\\DatSets\\\\glass.mat',\n",
    "                        squeeze_me=False)\n",
    "\n",
    "    enlist = list(data.items())\n",
    "    X = np.array(enlist, dtype=object)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 1)\n",
    "    y_true = np.empty([1,0], dtype=int)\n",
    "\n",
    "    #print(X[1][0][0])\n",
    "    k = 0\n",
    "    while k < len(X[1][0]):\n",
    "        y_true = np.append(y_true, int(X[1][0][k]))\n",
    "        k += 1\n",
    "\n",
    "    X = X[0][0]\n",
    "    \n",
    "   \n",
    "    # Fit the model\n",
    "    #plt.figure(figsize=(15, 12))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        #print(i + 1, 'fitting', clf_name)\n",
    "        # fit the data and tag outliers\n",
    "        p = 0\n",
    "        aps = []\n",
    "        #while p < 10:\n",
    "        clf.fit(X)\n",
    "        #WARNING put +1\n",
    "        scores_pred = clf.decision_function(X) * 1 \n",
    "        #threshold = percentile(scores_pred, 100 * outliers_fraction)\n",
    "        #y_pred = clf.predict(A) * -1\n",
    "        #y_pred = (y_pred + 1) / 2\n",
    "        #aps.append(average_precision_score(y_true, scores_pred))\n",
    "        #p += 1\n",
    "        #n_errors = (y_pred != ground_truth).sum()\n",
    "        # plot the levels lines and the points\n",
    "        #WARNING +1\n",
    "        #Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * 1\n",
    "        #Z = Z.reshape(xx.shape)\n",
    "        #plt.figure(figsize=[10,10])\n",
    "        #subplot = plt.subplot(2, 2, 1)\n",
    "        #subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "        #                 cmap=plt.cm.Blues_r)\n",
    "        #a = subplot.contour(xx, yy, Z, levels=[-threshold],\n",
    "        #                    linewidths=2, colors='red')\n",
    "        #subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "        #                 colors='orange')\n",
    "        #b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white',\n",
    "        #                    s=20, edgecolor='k')\n",
    "        #c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black',\n",
    "        #                    s=20, edgecolor='k')\n",
    "        #subplot.axis('tight')\n",
    "        #subplot.legend(\n",
    "         #   [a.collections[0], b, c],\n",
    "        #    ['learned decision function', 'true inliers', 'true outliers'],\n",
    "          #  prop=matplotlib.font_manager.FontProperties(size=10),\n",
    "          #  loc='lower right')\n",
    "        #subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "        #subplot.set_xlim((-7, 7))\n",
    "        #subplot.set_ylim((-7, 7))\n",
    "    #plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)\n",
    "    #plt.suptitle(\"Outlier detection\")\n",
    "#plt.show()\n",
    "plt.boxplot(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"save_vectors.ino\", \"w\")\n",
    "\n",
    "file.write(\"#include <vector>\\n\")\n",
    "file.write(\"using namespace std;\\n\\n\")\n",
    "file.write(\"struct Tree{\\n\")\n",
    "file.write(\"    int child_id_left, child_id_right, feature, n_samples;\\n\")\n",
    "file.write(\"    float threshold;\\n\")\n",
    "file.write(\"};\\n\\n\")\n",
    "\n",
    "file.write(\"vector<vector<Tree>> iForest;\\n\")\n",
    "m = 0\n",
    "while m < clf.n_estimators:\n",
    "    file.write(\"std::vector<Tree> iTree\" + str(m + 1) + \";\\n\")\n",
    "    m += 1\n",
    "file.write(\"\\n\")\n",
    "\n",
    "f = 0\n",
    "file.write(\"void setup() {\\n\")\n",
    "file.write(\"    Serial.begin(9600);\\n\")\n",
    "while f < clf.n_estimators:\n",
    "    j = 0\n",
    "    while j < len(clf.estimators_[f].tree_.feature):\n",
    "        temp_child_l = clf.estimators_[f].tree_.children_left[j]\n",
    "        if clf.estimators_[f].tree_.children_left[j] == -1:\n",
    "            temp_child_l = 0\n",
    "\n",
    "        temp_child_r = clf.estimators_[f].tree_.children_right[j]\n",
    "        if temp_child_r == clf.estimators_[f].tree_.children_right[j] == -1:\n",
    "            temp_child_r = 0\n",
    "\n",
    "        temp_feature = clf.estimators_[f].tree_.feature[j]\n",
    "        temp_threshold = clf.estimators_[f].tree_.threshold[j]\n",
    "        temps_values = clf.estimators_[f].tree_.n_node_samples[j]\n",
    "\n",
    "        file.write(\"    iTree\" + str(f + 1) + \".push_back({\"  \n",
    "                                                            + str(temp_child_l) + \", \"\n",
    "                                                            + str(temp_child_r) + \", \"\n",
    "                                                            + str(temp_feature) + \", \"\n",
    "                                                            + str(temps_values) + \", \"\n",
    "                                                            + str(temp_threshold) + \n",
    "                                                        \"});\\n\")\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    file.write(\"    iForest.push_back(iTree\" + str(f + 1) + \");\\n\\n\")\n",
    "    f += 1\n",
    "\n",
    "rows = f*j\n",
    "memory_per_vector = 8\n",
    "allocated_memory = rows * memory_per_vector\n",
    "file.write(\"}\\n\")\n",
    "file.write(\"void loop() {\\n\")\n",
    "file.write(\"\\n}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11807911085957218\n",
      "0.12029787628060881\n",
      "0.09952548955929473\n",
      "0.0865823468824918\n",
      "0.0628912175700369\n",
      "0.13123045644125098\n",
      "0.1226903992804477\n",
      "0.11905930369571788\n",
      "0.12700064006064504\n",
      "0.13703877093416741\n",
      "0.12452558920968751\n",
      "0.09268125147391848\n",
      "0.0393423189499267\n",
      "0.03366847870239827\n",
      "0.049188896011866434\n",
      "0.04153485412969061\n",
      "0.09620009222518025\n",
      "0.12594887320422643\n",
      "-0.10024505427206774\n",
      "0.12750946576119598\n",
      "-0.04284831337406653\n",
      "0.1469014652511538\n",
      "0.04415676919474365\n",
      "0.14600826346934268\n",
      "0.10821255718574911\n",
      "0.056908650948891554\n",
      "0.13546876803104774\n",
      "0.1255639540476783\n",
      "0.05081225400929133\n",
      "0.11511860278538458\n",
      "0.08323624236297461\n",
      "0.13715548293547714\n",
      "0.12496007869008445\n",
      "0.07107218834812654\n",
      "0.12982938348624096\n",
      "-0.01417149239900668\n",
      "0.11810201390794596\n",
      "0.10921932942746468\n",
      "0.11819667095404729\n",
      "0.11116268231983238\n",
      "0.11927645453629394\n",
      "0.11469709081102308\n",
      "0.0968695697269956\n",
      "0.07602720739571528\n",
      "-0.06250932324917928\n",
      "0.0835592585318279\n",
      "0.05569020003621094\n",
      "0.13209528323198644\n",
      "-0.007816599597804442\n",
      "0.10779101203592954\n",
      "0.09171543988162524\n",
      "0.09395227201230438\n",
      "0.1250523800161165\n",
      "0.037592843151358926\n",
      "0.11743001989379878\n",
      "0.08319098245374454\n",
      "0.08515995104345041\n",
      "0.1354158017735736\n",
      "0.08585713887577168\n",
      "0.056769430538441565\n",
      "0.13362024172127224\n",
      "0.13174911386657454\n",
      "0.11638440363140506\n",
      "0.06689359968080168\n",
      "0.048286798553287776\n",
      "0.1018988500229513\n",
      "0.11750283299999581\n",
      "0.09057678871959778\n",
      "-0.04504466325698557\n",
      "-0.1752606194362537\n",
      "0.11951446082205731\n",
      "0.10699225721863807\n",
      "0.14493627404710252\n",
      "0.004854469094164971\n",
      "0.1327786276991699\n",
      "0.10261390301785288\n",
      "0.0903945926399527\n",
      "0.11335470260320252\n",
      "0.09412634225905012\n",
      "0.08367814959456285\n",
      "0.11663007975912626\n",
      "0.12576368624437123\n",
      "0.08249535953565011\n",
      "0.07700810970977001\n",
      "0.041247580703682785\n",
      "-0.022433347900755417\n",
      "0.03273338851961245\n",
      "0.0951527500068527\n",
      "0.08922112038989025\n",
      "0.08048828187839059\n",
      "0.13510220461808511\n",
      "0.11562918241717313\n",
      "0.13359279223158238\n",
      "0.0388845457653415\n",
      "-0.025405920962020646\n",
      "0.14000434783121501\n",
      "0.1294389217652976\n",
      "0.1265129417785335\n",
      "0.1123211188726112\n",
      "0.06482494158778987\n",
      "0.06913739729816716\n",
      "0.14440203142479235\n",
      "0.10332611089983688\n",
      "0.09760217613905224\n",
      "0.11414506454424184\n",
      "0.11516920156036416\n",
      "0.11947987109520808\n",
      "0.1371911854822156\n",
      "0.06027168728511299\n",
      "0.11411496946067481\n",
      "0.08606004678596424\n",
      "0.1094343228455929\n",
      "0.06749794255704361\n",
      "0.05963203835453567\n",
      "0.09373579567668912\n",
      "0.11960163541994365\n",
      "0.05082994389739955\n",
      "0.1316247981006338\n",
      "0.09650202985286194\n",
      "0.025573676632371374\n",
      "0.09261656108552618\n",
      "0.07950481010819863\n",
      "0.11154608444981085\n",
      "0.01692836462240441\n",
      "0.10977900113975471\n",
      "0.14283699337975153\n",
      "0.1298911405912979\n",
      "0.10297490123702126\n",
      "0.12130521884375804\n",
      "0.1272555369249494\n",
      "0.08931853570367553\n",
      "0.05071734267430104\n",
      "0.13046946590261832\n",
      "0.09981354885630152\n",
      "0.019128408519234454\n",
      "0.10042802483965653\n",
      "0.1075348548903674\n",
      "0.12594226279703236\n",
      "0.07815175756401678\n",
      "0.08638073929443141\n",
      "0.10930363778417078\n",
      "0.09232930083368794\n",
      "0.09785060214986596\n",
      "0.001796035067489793\n",
      "0.11634536745005003\n",
      "-0.0780293732189638\n",
      "0.10658708063362272\n",
      "0.1170477357473122\n",
      "0.13677445290646043\n",
      "0.12975969082452515\n",
      "0.12144370725522653\n",
      "0.08400540908058793\n",
      "0.09598028505528858\n",
      "0.10081902689088562\n",
      "0.12164579550405637\n",
      "0.1094247048371327\n",
      "0.1344292588590666\n",
      "0.10481521940684078\n",
      "0.1037928332657611\n",
      "0.0511393510067472\n",
      "0.06432239702188534\n",
      "0.08742497339592752\n",
      "0.11929191754802926\n",
      "0.08000417541594937\n",
      "0.1313864441911618\n",
      "0.08834408759089558\n",
      "-0.03251566284656056\n",
      "0.08222187284141029\n",
      "0.09368820310757917\n",
      "-0.033207551513649465\n",
      "0.06835368194485603\n",
      "0.09052025933847316\n",
      "0.12058527625867965\n",
      "0.14124875252405902\n",
      "0.14125254014765892\n",
      "0.11309125272613518\n",
      "0.10568251314028508\n",
      "0.10749097147307948\n",
      "0.08029511543199225\n",
      "0.11271771464451727\n",
      "0.12058139164608163\n",
      "0.10476841582257591\n",
      "0.12852378912562057\n",
      "0.09655365012474693\n",
      "0.07865897714911192\n",
      "0.11697339303699704\n",
      "0.12619161439317297\n",
      "0.06563182426003822\n",
      "0.1343680930542384\n",
      "0.09691011852616452\n",
      "0.12519601693818644\n",
      "0.09758607703392469\n",
      "0.1153686266274293\n",
      "0.07848282862125104\n",
      "0.0875684465212797\n",
      "0.09654520543269193\n",
      "0.12783140182398836\n",
      "0.05770081676040446\n",
      "0.09634811739744605\n",
      "0.07100360583001528\n",
      "0.1338486161594644\n",
      "0.14691650897304098\n",
      "0.06496109587655274\n",
      "0.1291562964151515\n",
      "0.14018000436653655\n",
      "0.10204665433943388\n",
      "0.12359657460359137\n",
      "0.06431120750907243\n",
      "-0.0429132466533071\n",
      "0.09511817327523081\n",
      "0.10275650930310645\n",
      "0.08983831638913116\n",
      "0.1263833818510313\n",
      "0.049608222437624305\n",
      "0.10359369447398115\n",
      "0.12330654198900151\n",
      "0.12255384839581036\n",
      "0.10688690789682553\n",
      "0.04297694224965785\n",
      "0.11637806696089127\n",
      "0.024810954542058044\n",
      "0.1370212369827313\n",
      "0.12207722344233297\n",
      "0.10915896940130607\n",
      "0.10734812273476345\n",
      "0.11295001992320786\n",
      "0.14154169644248246\n",
      "0.125355003634626\n",
      "0.11069374808863598\n",
      "0.12461429611398982\n",
      "0.10755605699502498\n",
      "0.12361362092346491\n",
      "0.08103043740700473\n",
      "0.07339224934396095\n",
      "0.12272170244917066\n",
      "0.118327032546891\n",
      "0.1348261474859783\n",
      "0.06342082987390252\n",
      "0.0877332275851844\n",
      "0.12930962390664952\n",
      "0.06668791124111978\n",
      "0.1296221151505709\n",
      "0.12206041757718583\n",
      "0.13303798501313066\n",
      "0.006761435622463259\n",
      "0.12558781445504083\n",
      "0.10912692834847602\n",
      "0.031018990224842655\n",
      "0.08903480855274512\n",
      "0.10957902104221262\n",
      "0.1264272636285357\n",
      "0.11041881183124307\n",
      "0.1161519401594432\n",
      "0.10654762329611368\n",
      "0.1271992135246145\n",
      "0.13044684073781967\n",
      "0.12575336210237675\n",
      "0.12134810682549978\n",
      "0.11761160600389733\n",
      "0.06985980440572005\n",
      "0.09674286211591801\n",
      "0.07219506725209811\n",
      "0.11941674891588613\n",
      "0.10991528775986124\n",
      "0.10360883370028673\n",
      "0.053279220117107916\n",
      "0.10919359808492346\n",
      "0.10562789800099266\n",
      "0.12914108791302903\n",
      "0.07883057930506583\n",
      "0.083614965407369\n",
      "0.1188373222118873\n",
      "0.11286570394620052\n",
      "0.07897778897032032\n",
      "0.09504557300608123\n",
      "0.13408775217302105\n",
      "0.1196299582902646\n",
      "0.02262734625299005\n",
      "0.10426499634785806\n",
      "0.10664622056654992\n",
      "0.05732306978704217\n",
      "0.1116952510680677\n",
      "0.05990706788962366\n",
      "0.08823168186194498\n",
      "0.022564560812565616\n",
      "0.08250148622203494\n",
      "0.12108340554415656\n",
      "0.09641163759338485\n",
      "0.10238939046425148\n",
      "0.13106797194272216\n",
      "0.13561486684832294\n",
      "0.11571910292987124\n",
      "0.102202998296326\n",
      "0.13046424830726056\n",
      "0.03851152485838855\n",
      "0.0006640725388821097\n",
      "0.10407349587112842\n",
      "0.13116455053139364\n",
      "0.1270543045675942\n",
      "-0.03388489778470687\n",
      "0.09341248139339388\n",
      "0.12011806323474891\n",
      "0.11020412392169225\n",
      "0.09625958103600864\n",
      "0.1287292506118849\n",
      "0.07498394081953308\n",
      "0.11924441763566405\n",
      "-0.049806466640064384\n",
      "-0.05542911718364109\n",
      "0.10764693014391175\n",
      "0.06631308596011157\n",
      "0.06656918168620189\n",
      "0.09615686933712295\n",
      "0.10916912918509439\n",
      "0.09701218279151842\n",
      "0.1306524296029624\n",
      "0.08126744282284223\n",
      "0.1223918539889724\n",
      "0.02459463269564376\n",
      "0.1040526629342019\n",
      "0.12317393596505172\n",
      "0.11165109720518118\n",
      "0.05541101549126817\n",
      "0.09983403556450995\n",
      "0.10247610773073965\n",
      "0.010937345537601551\n",
      "0.1281737058849875\n",
      "0.11618757428078699\n",
      "0.11917123093605207\n",
      "0.1197419998090986\n",
      "0.10565565123884584\n",
      "0.04264363430715949\n",
      "-0.0016035169795790894\n",
      "-0.03156152188216761\n",
      "0.10776886401498241\n",
      "0.06664950176125445\n",
      "0.10281027482387121\n",
      "0.10951770733552768\n",
      "0.1288499252709976\n",
      "0.12816107599174048\n",
      "0.11427879944152167\n",
      "0.0961186335480102\n",
      "0.115793500288235\n",
      "0.08825625005334281\n",
      "0.08482656005035458\n",
      "0.11273657033566488\n",
      "0.10290463858767875\n",
      "0.07339814559275472\n",
      "0.10616814708919571\n",
      "0.07097551607997818\n",
      "0.09753373759134741\n",
      "0.019069503444549333\n",
      "0.07288451082295781\n",
      "0.06483363715966384\n",
      "0.09145328221538929\n",
      "-0.012442322730911698\n",
      "0.008440170840966866\n",
      "0.061046193887076924\n",
      "-0.16654011716778117\n",
      "0.031240387881704357\n",
      "-0.07869106168265094\n",
      "-0.06934906370636658\n",
      "-0.12222624438618049\n",
      "-0.018777178484703054\n",
      "-0.17539646751634955\n",
      "0.06034267379334364\n",
      "-0.12227810127595719\n",
      "-0.030685020896643173\n",
      "-0.12764143169328906\n",
      "0.07735423160080686\n",
      "-0.049902571900396535\n",
      "0.03208118233137011\n",
      "-0.10999699703688944\n",
      "-0.032879071883091755\n",
      "0.061046193887076924\n",
      "-0.24997160502759533\n",
      "-0.1997699369973191\n",
      "-0.0025564959703430258\n"
     ]
    }
   ],
   "source": [
    "# Fit the models with the generated data and \n",
    "# compare model performances\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    #X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    #X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    #X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    #X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "    data = scipy.io.loadmat('C:\\\\Users\\\\anton\\\\OneDrive\\\\Skrivbord\\\\Thesis_Code\\\\IsolationForestTinyML\\\\DatSets\\\\mnist.mat',\n",
    "                        squeeze_me=False)\n",
    "\n",
    "    enlist = list(data.items())\n",
    "    X = np.array(enlist, dtype=object)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 1)\n",
    "\n",
    "    y_true = np.empty([1,0], dtype=int)\n",
    "\n",
    "    #print(X[1][0][0])\n",
    "    k = 0\n",
    "    while k < len(X[1][0]):\n",
    "        y_true = np.append(y_true, int(X[1][0][k]))\n",
    "        k += 1\n",
    "\n",
    "    X = X[0][0]\n",
    "    # Fit the model\n",
    "    #plt.figure(figsize=(15, 12))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        #print(i + 1, 'fitting', clf_name)\n",
    "        # fit the data and tag outliers\n",
    "        p = 0\n",
    "        aps = []\n",
    "        all_scores = []\n",
    "        while p < 10:\n",
    "            clf.fit(X)\n",
    "            #WARNING put +1\n",
    "            scores_pred = clf.decision_function(X) * 1 \n",
    "            #threshold = percentile(scores_pred, 100 * outliers_fraction)\n",
    "            #y_pred = clf.predict(X) * -1\n",
    "            #y_pred = (y_pred + 1) / 2\n",
    "            #aps.append(average_precision_score(y_true, scores_pred))\n",
    "            all_scores.append(scores_pred)\n",
    "            p += 1\n",
    "\n",
    "    r = 0\n",
    "    average_scores = []\n",
    "\n",
    "    while r < len(all_scores[0]):\n",
    "        c = 0\n",
    "        avg = 0\n",
    "        while c < len(all_scores):\n",
    "            avg += all_scores[c][r]/10\n",
    "            c += 1\n",
    "        average_scores.append(avg)\n",
    "        r += 1\n",
    "\n",
    "    for a in average_scores:\n",
    "        print(a)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22088ef271373e2cbf099a2df3479705078d4b70103bf40dba9301d6ee5dcef5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
