{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "from sklearn.metrics import average_precision_score\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of inliers and outliers\n",
    "n_samples = 256\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0]\n",
    "\n",
    "# Compare given detectors under given settings\n",
    "# Initialize the data\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.zeros(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(42)\n",
    "# Define nine outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    'Isolation Forest': IsolationForest(contamination=outliers_fraction,\n",
    "                                random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x249785311c0>,\n",
       "  <matplotlib.lines.Line2D at 0x24978531490>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x24978531820>,\n",
       "  <matplotlib.lines.Line2D at 0x24978531a30>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x24978516eb0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x24978531d00>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x24978531fd0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the models with the generated data and \n",
    "# compare model performances\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    #X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    #X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    #X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    #X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "    data = scipy.io.loadmat('C:\\\\Users\\\\anton\\\\OneDrive\\\\Skrivbord\\\\Thesis_Code\\\\IsolationForestTinyML\\\\DatSets\\\\wine.mat',\n",
    "                        squeeze_me=False)\n",
    "\n",
    "    enlist = list(data.items())\n",
    "    X = np.array(enlist, dtype=object)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 1)\n",
    "\n",
    "    y_true = np.empty([1,0], dtype=int)\n",
    "\n",
    "    #print(X[1][0][0])\n",
    "    k = 0\n",
    "    while k < len(X[1][0]):\n",
    "        y_true = np.append(y_true, int(X[1][0][k]))\n",
    "        k += 1\n",
    "\n",
    "    X = X[0][0]\n",
    "    # Fit the model\n",
    "    #plt.figure(figsize=(15, 12))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        #print(i + 1, 'fitting', clf_name)\n",
    "        # fit the data and tag outliers\n",
    "        p = 0\n",
    "        aps = []\n",
    "        while p < 10:\n",
    "            clf.fit(X)\n",
    "            #WARNING put +1\n",
    "            scores_pred = clf.decision_function(X) * 1 \n",
    "            threshold = percentile(scores_pred, 100 * outliers_fraction)\n",
    "            y_pred = clf.predict(X) * -1\n",
    "            y_pred = (y_pred + 1) / 2\n",
    "            aps.append(average_precision_score(y_true, scores_pred))\n",
    "            p += 1\n",
    "        #n_errors = (y_pred != ground_truth).sum()\n",
    "        # plot the levels lines and the points\n",
    "        #WARNING +1\n",
    "        #Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * 1\n",
    "        #Z = Z.reshape(xx.shape)\n",
    "        #plt.figure(figsize=[10,10])\n",
    "        #subplot = plt.subplot(2, 2, 1)\n",
    "        #subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "        #                 cmap=plt.cm.Blues_r)\n",
    "        #a = subplot.contour(xx, yy, Z, levels=[-threshold],\n",
    "        #                    linewidths=2, colors='red')\n",
    "        #subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "        #                 colors='orange')\n",
    "        #b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white',\n",
    "        #                    s=20, edgecolor='k')\n",
    "        #c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black',\n",
    "        #                    s=20, edgecolor='k')\n",
    "        #subplot.axis('tight')\n",
    "        #subplot.legend(\n",
    "         #   [a.collections[0], b, c],\n",
    "        #    ['learned decision function', 'true inliers', 'true outliers'],\n",
    "          #  prop=matplotlib.font_manager.FontProperties(size=10),\n",
    "          #  loc='lower right')\n",
    "        #subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "        #subplot.set_xlim((-7, 7))\n",
    "        #subplot.set_ylim((-7, 7))\n",
    "    #plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)\n",
    "    #plt.suptitle(\"Outlier detection\")\n",
    "#plt.show()\n",
    "plt.boxplot(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,  -1,   7,  -1,  -1,  10,  -1,  12,  13,\n",
       "        14,  -1,  -1,  -1,  -1,  19,  20,  21,  -1,  -1,  -1,  -1,  26,\n",
       "        27,  28,  29,  30,  31,  -1,  -1,  34,  -1,  -1,  37,  38,  -1,\n",
       "        -1,  41,  -1,  -1,  44,  45,  46,  -1,  -1,  49,  -1,  -1,  52,\n",
       "        -1,  54,  -1,  -1,  57,  -1,  59,  -1,  -1,  62,  63,  64,  65,\n",
       "        -1,  67,  -1,  -1,  70,  71,  -1,  -1,  -1,  -1,  -1,  77,  78,\n",
       "        79,  80,  81,  -1,  83,  84,  -1,  -1,  -1,  88,  89,  -1,  -1,\n",
       "        92,  93,  -1,  -1,  96,  -1,  -1,  99, 100,  -1,  -1, 103,  -1,\n",
       "       105, 106,  -1,  -1,  -1, 110, 111, 112,  -1,  -1,  -1, 116, 117,\n",
       "        -1, 119,  -1,  -1,  -1, 123, 124, 125, 126, 127, 128,  -1,  -1,\n",
       "        -1, 132, 133,  -1,  -1, 136,  -1,  -1, 139, 140,  -1, 142,  -1,\n",
       "        -1,  -1, 146, 147, 148,  -1,  -1, 151, 152,  -1,  -1, 155,  -1,\n",
       "        -1,  -1, 159, 160,  -1, 162, 163, 164,  -1,  -1,  -1, 168, 169,\n",
       "        -1,  -1, 172,  -1,  -1, 175,  -1,  -1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf.estimators_[0].tree_.children_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(clf.estimators_[0].tree_.children_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  1,  5, 10,  6, -2,  6, -2, -2,  6, -2,  5, 12,  8, -2, -2, -2,\n",
       "       -2,  4,  9,  6, -2, -2, -2, -2,  2,  8,  3,  1,  9,  6, -2, -2,  4,\n",
       "       -2, -2,  6,  1, -2, -2,  6, -2, -2, 11,  2,  4, -2, -2,  3, -2, -2,\n",
       "        1, -2, 11, -2, -2,  1, -2,  9, -2, -2,  2, 11,  5,  7, -2,  2, -2,\n",
       "       -2,  4,  9, -2, -2, -2, -2, -2, 11,  7,  9,  9, 12, -2,  2, 12, -2,\n",
       "       -2, -2,  0,  8, -2, -2, 10,  0, -2, -2,  2, -2, -2,  0,  1, -2, -2,\n",
       "        7, -2,  6, 12, -2, -2, -2,  7,  8,  7, -2, -2, -2, 10,  9, -2, 10,\n",
       "       -2, -2, -2, 10, 11, 10, 10,  6,  6, -2, -2, -2,  0,  6, -2, -2, 12,\n",
       "       -2, -2,  0,  8, -2, 11, -2, -2, -2,  1,  5, 12, -2, -2, 11,  1, -2,\n",
       "       -2,  6, -2, -2, -2,  3,  0, -2,  1,  3,  4, -2, -2, -2,  4,  5, -2,\n",
       "       -2,  3, -2, -2,  5, -2, -2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.estimators_[0].tree_.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.estimators_[0].tree_.threshold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "# Fit the models with the generated data and \n",
    "# compare model performances\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    #X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    #X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    #X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    #X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "    data = scipy.io.loadmat('C:\\\\Users\\\\anton\\\\OneDrive\\\\Skrivbord\\\\Thesis_Code\\\\IsolationForestTinyML\\\\DatSets\\\\wine.mat',\n",
    "                        squeeze_me=False)\n",
    "\n",
    "    enlist = list(data.items())\n",
    "    X = np.array(enlist, dtype=object)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 0)\n",
    "    X = np.delete(X, 0, 1)\n",
    "\n",
    "    y_true = np.empty([1,0], dtype=int)\n",
    "\n",
    "    #print(X[1][0][0])\n",
    "    k = 0\n",
    "    while k < len(X[1][0]):\n",
    "        y_true = np.append(y_true, int(X[1][0][k]))\n",
    "        k += 1\n",
    "\n",
    "    X = X[0][0]\n",
    "    # Fit the model\n",
    "    #plt.figure(figsize=(15, 12))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        #print(i + 1, 'fitting', clf_name)\n",
    "        # fit the data and tag outliers\n",
    "        p = 0\n",
    "        aps = []\n",
    "        while p < 10:\n",
    "            clf.fit(X)\n",
    "            #WARNING put +1\n",
    "            scores_pred = clf.decision_function(X) * 1 \n",
    "            threshold = percentile(scores_pred, 100 * outliers_fraction)\n",
    "            y_pred = clf.predict(X) * -1\n",
    "            y_pred = (y_pred + 1) / 2\n",
    "            aps.append(average_precision_score(y_true, scores_pred))\n",
    "            p += 1\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(X)\n",
    "\n",
    "    max = scaler.data_max_\n",
    "    min = scaler.data_min_\n",
    "\n",
    "    norm_data = scaler.transform(X)\n",
    "\n",
    "    print(len(norm_data))\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"save_vectors.ino\", \"w\")\n",
    "\n",
    "file.write(\"#include <vector>\\n\")\n",
    "file.write(\"using namespace std;\\n\\n\")\n",
    "file.write(\"struct Tree{\\n\")\n",
    "file.write(\"    int child_id_left, child_id_right, feature, n_samples;\\n\")\n",
    "file.write(\"    float threshold;\\n\")\n",
    "file.write(\"};\\n\\n\")\n",
    "\n",
    "file.write(\"vector<vector<Tree>> iForest;\\n\")\n",
    "m = 0\n",
    "while m < clf.n_estimators:\n",
    "    file.write(\"std::vector<Tree> iTree\" + str(m + 1) + \";\\n\")\n",
    "    m += 1\n",
    "file.write(\"\\n\")\n",
    "\n",
    "f = 0\n",
    "file.write(\"void setup() {\\n\")\n",
    "file.write(\"    Serial.begin(9600);\\n\")\n",
    "while f < clf.n_estimators:\n",
    "    j = 0\n",
    "    while j < len(clf.estimators_[f].tree_.feature):\n",
    "        temp_child_l = clf.estimators_[f].tree_.children_left[j]\n",
    "        if clf.estimators_[f].tree_.children_left[j] == -1:\n",
    "            temp_child_l = 0\n",
    "\n",
    "        temp_child_r = clf.estimators_[f].tree_.children_right[j]\n",
    "        if temp_child_r == clf.estimators_[f].tree_.children_right[j] == -1:\n",
    "            temp_child_r = 0\n",
    "\n",
    "        temp_feature = clf.estimators_[f].tree_.feature[j]\n",
    "        temp_threshold = clf.estimators_[f].tree_.threshold[j]\n",
    "        temps_values = clf.estimators_[f].tree_.n_node_samples[j]\n",
    "\n",
    "        file.write(\"    iTree\" + str(f + 1) + \".push_back({\"  \n",
    "                                                            + str(temp_child_l) + \", \"\n",
    "                                                            + str(temp_child_r) + \", \"\n",
    "                                                            + str(temp_feature) + \", \"\n",
    "                                                            + str(temps_values) + \", \"\n",
    "                                                            + str(temp_threshold) + \n",
    "                                                        \"});\\n\")\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    file.write(\"    iForest.push_back(iTree\" + str(f + 1) + \");\\n\\n\")\n",
    "    f += 1\n",
    "\n",
    "rows = f*j\n",
    "memory_per_vector = 8\n",
    "allocated_memory = rows * memory_per_vector\n",
    "file.write(\"}\\n\")\n",
    "file.write(\"void loop() {\\n\")\n",
    "file.write(\"}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anton\\OneDrive\\Skrivbord\\Thesis_Code\\IsolationForestTinyML\\PyOffline_solution\\sciForest.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anton/OneDrive/Skrivbord/Thesis_Code/IsolationForestTinyML/PyOffline_solution/sciForest.ipynb#ch0000008?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m s \u001b[39m<\u001b[39m clf\u001b[39m.\u001b[39mn_estimators:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anton/OneDrive/Skrivbord/Thesis_Code/IsolationForestTinyML/PyOffline_solution/sciForest.ipynb#ch0000008?line=6'>7</a>\u001b[0m     new_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdelete(clf\u001b[39m.\u001b[39mestimators_[s]\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mthreshold, np\u001b[39m.\u001b[39mwhere(clf\u001b[39m.\u001b[39mestimators_[s]\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mthreshold \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anton/OneDrive/Skrivbord/Thesis_Code/IsolationForestTinyML/PyOffline_solution/sciForest.ipynb#ch0000008?line=7'>8</a>\u001b[0m     scale \u001b[39m=\u001b[39m (\u001b[39mmax\u001b[39;49m(new_arr)\u001b[39m-\u001b[39m\u001b[39mmin\u001b[39m(new_arr))\u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/OneDrive/Skrivbord/Thesis_Code/IsolationForestTinyML/PyOffline_solution/sciForest.ipynb#ch0000008?line=9'>10</a>\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/OneDrive/Skrivbord/Thesis_Code/IsolationForestTinyML/PyOffline_solution/sciForest.ipynb#ch0000008?line=10'>11</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(clf\u001b[39m.\u001b[39mestimators_[s]\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mthreshold):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#open file\n",
    "file = open('data.txt' , 'w')\n",
    "\n",
    "s = 0\n",
    "while s < clf.n_estimators:\n",
    "\n",
    "    new_arr = np.delete(clf.estimators_[s].tree_.threshold, np.where(clf.estimators_[s].tree_.threshold == -2))\n",
    "    scale = (max(new_arr)-min(new_arr))/ 255\n",
    "\n",
    "    i = 0\n",
    "    while i < len(clf.estimators_[s].tree_.threshold):\n",
    "\n",
    "        if int(clf.estimators_[s].tree_.threshold[i]) != -2:\n",
    "            quant = round(clf.estimators_[s].tree_.threshold[i]/scale - min(new_arr)) #Correct formula?\n",
    "            clf.estimators_[s].tree_.threshold[i] = quant\n",
    "        else:\n",
    "            clf.estimators_[s].tree_.threshold[i] = clf.estimators_[s].tree_.threshold[i]\n",
    "            \n",
    "        i += 1\n",
    "    file.write(str(s + 1))\n",
    "    d = 0\n",
    "    while d < len(clf.estimators_[s].tree_.feature):\n",
    "        file.write(\" \" + str(clf.estimators_[s].tree_.children_left[d]))\n",
    "        file.write(\" \" + str(clf.estimators_[s].tree_.children_right[d]))\n",
    "        file.write(\" \" + str(clf.estimators_[s].tree_.feature[d]))\n",
    "        file.write(\" \" + str(int(clf.estimators_[s].tree_.threshold[d])))\n",
    "        file.write(\" \" + str(clf.estimators_[s].tree_.n_node_samples[d]))\n",
    "        d += 1\n",
    "    \n",
    "    file.write(\"\\n\")\n",
    "    s += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4a31993002339e453ebb2c66c294fd01e84ed8cca375c93fb5e33ef382fbc8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
